{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "#!pip install pypyodbc\n",
    "#!pip install pyodbc\n",
    "\n",
    "import pypyodbc\n",
    "import pyodbc\n",
    "\n",
    "import statsmodels.api as sm #Modelos estadistico y metodologías econometricas\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller #Pruebas de raíz unitaria ads,kpss,ers\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose #Análisis de estacionalidad\n",
    "\n",
    "import statsmodels.graphics.tsaplots as sgt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "\n",
    "import sklearn as sk\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.distributions import chi2\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4d9951f68868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msql_queryx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:,.0f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msql_queryx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Infra'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql_queryx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Infra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msql_queryx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Maq'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql_queryx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Maq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msql_queryx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Infra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "sql_queryx = pd.read_excel (r\"\")\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "sql_queryx['Infra'] = sql_queryx['Infra'].cumsum().shift(-4)\n",
    "sql_queryx['Maq'] = sql_queryx['Maq'].cumsum().shift(-4)\n",
    "sql_queryx.dropna(subset = ['Infra'], inplace=True)\n",
    "#sql_queryx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantenimiento e Inversión en XXXX - Modelo OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sql_queryx['Infra']\n",
    "y = sql_queryx['Mant_inf']\n",
    "# X = sm.add_constant(X)\n",
    "result1 = sm.OLS(y, X.astype(float)).fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prstd, iv_l, iv_u = wls_prediction_std(result1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(X, y, 'o', label=\"data\")\n",
    "#ax.plot(X, result1.predict(), 'y-', label=\"Predict\")\n",
    "ax.plot(X, result1.fittedvalues, 'b--.', label=\"OLS\")\n",
    "ax.plot(X, iv_u, 'r--')\n",
    "ax.plot(X, iv_l, 'r--')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig = sm.graphics.plot_fit(result1, 0, ax=ax)\n",
    "ax.set_ylabel(\"Infraestructura\")\n",
    "ax.set_xlabel(\"Mantenimiento\")\n",
    "ax.set_title(\"Linear Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantenimiento e Inversión enXXXX - Modelo SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimación en Niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(endog=y, exog =X, order=(0,0,4))\n",
    "result2 = model.fit()\n",
    "print(result2.summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimación en Tasas de Crecimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sql_queryx['Infra']\n",
    "\n",
    "result = sts.adfuller(X)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sql_queryx['Mant_inf']\n",
    "\n",
    "result = sts.adfuller(y)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna de las series son estacionarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_logged_diff_x = sql_queryx['Infra'].pct_change()\n",
    "\n",
    "df_logged_x = sql_queryx['Infra'].apply(lambda x : np.log(x))\n",
    "\n",
    "df_logged_diff_x = df_logged_x - df_logged_x.shift()\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "df_logged_diff_x.plot(figsize=(12,4), color=\"tab:red\", title=\"Differenced Time-Series\", ax=ax1)\n",
    "ax2 = plt.subplot(122)\n",
    "sql_queryx['Infra'].plot(figsize=(12,4), color=\"tab:red\", title=\"Original Values\", ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_logged_diff = sql_queryx['Mant_inf'].pct_change()\n",
    "\n",
    "df_logged = sql_queryx['Mant_inf'].apply(lambda x : np.log(x))\n",
    "\n",
    "df_logged_diff = df_logged - df_logged.shift()\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "df_logged_diff.plot(figsize=(12,4), color=\"tab:red\", title=\"Differenced Time-Series\", ax=ax1)\n",
    "ax2 = plt.subplot(122)\n",
    "sql_queryx['Mant_inf'].plot(figsize=(12,4), color=\"tab:red\", title=\"Original Values\", ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1=pd.DataFrame(df_logged_diff)\n",
    "db2 = pd.DataFrame(df_logged_diff_x)\n",
    "db1 = db1.iloc[1:,]\n",
    "db2 = db2.iloc[1:,]\n",
    "db_new=pd.concat([db1,db2], axis=1)\n",
    "#db_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = db_new['Infra']\n",
    "\n",
    "result = sts.adfuller(X)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = db_new['Mant_inf']\n",
    "\n",
    "result = sts.adfuller(y)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 2)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 4) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(db_new['Mant_inf'],\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "\n",
    "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', message='foo bar')\n",
    "model = sm.tsa.statespace.SARIMAX(endog=db_new.Mant_inf, exog =db_new.Infra, order=(0,0,1))\n",
    "results = model.fit()\n",
    "print(results.summary());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(10, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=0,  dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "#pred_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = db_new['Mant_inf'].plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)\n",
    "\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Mantenimiento')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_new.Infra[0:8,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_uc = results.get_forecast(steps=8, exog=db_new.Infra[0:8,])\n",
    "\n",
    "# Get confidence intervals of forecasts\n",
    "pred_ci = pred_uc.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y.plot(label='observed', figsize=(20, 15))\n",
    "pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('CO2 Levels')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = pred.predicted_mean\n",
    "db_n = pd.DataFrame(ti, columns = ['mant_rate_hat'])\n",
    "db_n['FECHA'] = pd.date_range('2007-04-05', periods=57, freq='Q')\n",
    "db_n['mant_rate'] = y\n",
    "db_n['infra_rate'] = X\n",
    "db_n['error'] = y - db_n['mant_rate_hat']\n",
    "db_n['Mant_inf'] = sql_queryx['Mant_inf']\n",
    "db_n['Infra'] = sql_queryx['Infra']\n",
    "db_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast= pred_uc.predicted_mean\n",
    "db1 = pd.DataFrame(forecast, columns = ['mant_rate_hat'])\n",
    "db1['FECHA']= pd.date_range('2021-07-01', periods=8, freq='Q')\n",
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mantenimiento_infra = pd.concat([db_n, db1], axis=0)\n",
    "mantenimiento_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hola = mantenimiento_infra.copy()\n",
    "hola['predi1'] = hola['Mant_inf'].shift()*np.exp(hola['mant_rate'])\n",
    "hola['predi2'] = hola['predi1'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi3']  = hola['predi2'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi4']  = hola['predi3'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi5']  = hola['predi4'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi6']  = hola['predi5'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi7']  = hola['predi6'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi8']  = hola['predi7'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "hola['predi9']  = hola['predi8'].shift()*np.exp(hola['mant_rate_hat'])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "\n",
    "hola['date2'] = datetime.datetime(2021, 9, 30)\n",
    "hola['date3'] = datetime.datetime(2021, 12, 31)\n",
    "hola['date4'] = datetime.datetime(2022, 3, 31)\n",
    "hola['date5'] = datetime.datetime(2022, 6, 30)\n",
    "hola['date6'] = datetime.datetime(2022, 9, 30)\n",
    "hola['date7'] = datetime.datetime(2022, 12, 31)\n",
    "hola['date8'] = datetime.datetime(2023, 3, 31)\n",
    "hola['date9'] = datetime.datetime(2023, 6, 30)\n",
    "\n",
    "def fecha(row):\n",
    "    if row['FECHA'] == row['date2']:\n",
    "        clasifico = row['predi2']\n",
    "    elif row['FECHA'] == row['date3']:\n",
    "        clasifico = row['predi3']\n",
    "    elif row['FECHA'] == row['date4']:\n",
    "        clasifico = row['predi4']\n",
    "    elif row['FECHA'] == row['date5']:\n",
    "        clasifico = row['predi5']\n",
    "    elif row['FECHA'] == row['date6']:\n",
    "        clasifico = row['predi6']\n",
    "    elif row['FECHA'] == row['date7']:\n",
    "        clasifico = row['predi7']\n",
    "    elif row['FECHA'] == row['date8']:\n",
    "        clasifico = row['predi8']\n",
    "    elif row['FECHA'] == row['date9']:\n",
    "        clasifico = row['predi9']\n",
    "    elif row['Mant_inf'] != 0 and row['Mant_inf'] != 'nan':\n",
    "        clasifico = row['Mant_inf']\n",
    "    else:\n",
    "        clasifico = 'no'\n",
    "    return clasifico\n",
    "\n",
    "hola['mant_level_hat'] = hola.apply(fecha, axis=1)\n",
    "\n",
    "infraestructura = hola[['FECHA','Mant_inf','Infra','mant_rate','mant_rate_hat','infra_rate','error','mant_level_hat']]\n",
    "infraestructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infraestructura.to_csv(r'G:\\.shortcut-targets-by-id\\1CvCex95agcRH6L6KPy5QTdP2_XJoAUNX\\02. Investment (I)\\7. Reportes\\3. Consultas\\Analitico\\Inversiones\\Gino\\Pruebas\\Infraestructura_resultados.csv', sep=';', encoding='iso-8859-1',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantenimiento e Inversión en XXXX - Modelo OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sql_queryx['Maq']\n",
    "y = sql_queryx['Mant_maq']\n",
    "# X = sm.add_constant(X)\n",
    "res1 = sm.OLS(y, X.astype(float)).fit()\n",
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prstd, iv_l, iv_u = wls_prediction_std(res1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(X, y, 'o', label=\"data\")\n",
    "#ax.plot(X, result1.predict(), 'y-', label=\"Predict\")\n",
    "ax.plot(X, res1.fittedvalues, 'b--.', label=\"OLS\")\n",
    "ax.plot(X, iv_u, 'r--')\n",
    "ax.plot(X, iv_l, 'r--')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig = sm.graphics.plot_fit(res1, 0, ax=ax)\n",
    "ax.set_ylabel(\"Mantenimiento de Equipos\")\n",
    "ax.set_xlabel(\"Inversión en Equipos\")\n",
    "ax.set_title(\"Linear Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantenimiento e Inversión en XXXX - Modelo SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimación en Niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(endog=y, exog =X, order=(0,0,4))\n",
    "res3 = model.fit()\n",
    "print(res3.summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimación en Tasa de Crecimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sql_queryx['Maq']\n",
    "\n",
    "result = sts.adfuller(X)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sql_queryx['Mant_maq']\n",
    "\n",
    "result = sts.adfuller(y)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logged_x = sql_queryx['Maq'].apply(lambda x : np.log(x))\n",
    "\n",
    "df_logged_diff_x = df_logged_x - df_logged_x.shift()\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "df_logged_diff_x.plot(figsize=(12,4), color=\"tab:red\", title=\"Differenced Time-Series\", ax=ax1)\n",
    "ax2 = plt.subplot(122)\n",
    "sql_queryx['Infra'].plot(figsize=(12,4), color=\"tab:red\", title=\"Original Values\", ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logged = sql_queryx['Mant_maq'].apply(lambda x : np.log(x))\n",
    "\n",
    "df_logged_diff = df_logged- df_logged.shift()\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "df_logged_diff.plot(figsize=(12,4), color=\"tab:red\", title=\"Differenced Time-Series\", ax=ax1)\n",
    "ax2 = plt.subplot(122)\n",
    "sql_queryx['Infra'].plot(figsize=(12,4), color=\"tab:red\", title=\"Original Values\", ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df_logged_diff)\n",
    "df2 = pd.DataFrame(df_logged_diff_x)\n",
    "df1 = df1.iloc[1:,]\n",
    "df2 = df2.iloc[1:,]\n",
    "db_new1=pd.concat([df1,df2], axis=1)\n",
    "#db_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF Test\n",
    "X = db_new1['Maq']\n",
    "\n",
    "result = sts.adfuller(X)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF Test\n",
    "y = db_new1['Mant_maq']\n",
    "\n",
    "result = sts.adfuller(y)\n",
    "print('Null Hypothesis(H0): Serie has a unit root')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "print('Numbers of lag used         : %f' % result[2])\n",
    "print('Numbers of observations used: %f' % result[3])\n",
    "print('Criterio de Información     : %f' % result[5])\n",
    "\n",
    "ADF=result[0]\n",
    "Critical=result[4].get('10%')\n",
    "if ADF<Critical:\n",
    "    print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria')\n",
    "elif Critical<ADF:\n",
    "    print('No se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie tiene raíz unitaria, entonces es no estacionaria')\n",
    "else: print('Se rechaza H0, de rechazar H0 la probabilidad de equivocarnos sería %f' % result[1]+'\\nPor tanto: La serie no tiene raíz unitaria, entonces es estacionaria') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(db_new1['Mant_maq'],\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "\n",
    "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(endog=db_new1.Mant_maq, exog =db_new1.Maq, order=(0,0,1))\n",
    "results2 = model.fit()\n",
    "print(results2.summary());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.plot_diagnostics(figsize=(10, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results2.get_prediction(start=0,  dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "#pred_ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = db_new1['Mant_maq'].plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)\n",
    "\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Mantenimiento')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_new1['mant_rate'] = db_new1['Mant_maq']\n",
    "db_new1['mant_rate_hat']= pred.predicted_mean\n",
    "db_new1['maq_rate'] = db_new1['Maq']\n",
    "db_new1['error'] = db_new1['Mant_maq'] - db_new1['mant_rate_hat']\n",
    "db_new1['Mant_maq'] = sql_queryx['Mant_maq']\n",
    "db_new1['Maq'] = sql_queryx['Maq']\n",
    "db_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_new1.to_csv(r'G:\\.shortcut-targets-by-id\\1CvCex95agcRH6L6KPy5QTdP2_XJoAUNX\\02. Investment (I)\\7. Reportes\\3. Consultas\\Analitico\\Inversiones\\Gino\\Pruebas\\Equipos_results.csv', sep=';', encoding='iso-8859-1')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
